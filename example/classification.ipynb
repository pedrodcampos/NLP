{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "import contractions\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "stop_punctuation = [p for p in punctuation]\n",
    "stoppers = stop_words+stop_punctuation\n",
    "stoppers.remove('not')\n",
    "\n",
    "def clean_and_tokenize(txt):\n",
    "    def get_wordnet_pos(tag):\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "        return tag_dict.get(tag[0], wordnet.NOUN)\n",
    "\n",
    "    sentences = sent_tokenize(txt)\n",
    "    cleaned_txt = []\n",
    "    for sentence in sentences:\n",
    "        expanded_sentences = contractions.fix(sentence)\n",
    "        tokens = [token for token in word_tokenize(expanded_sentences)]\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        for token, tag in tagged_tokens:\n",
    "            if len(token)>2:\n",
    "                lemma_word = lemmatizer.lemmatize(token,get_wordnet_pos(tag))\n",
    "                if lemma_word not in stoppers:\n",
    "                    stemmed_word = stemmer.stem(lemma_word)\n",
    "                    cleaned_txt.append(stemmed_word)\n",
    "    return \" \".join(cleaned_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array([['a dog barks','dog'],\n",
    "                          ['dogs are friendly animals','dog'],\n",
    "                          ['her pet won\\'t stop barking','dog'],\n",
    "                          ['bob is wagging his tail. He is very firendly','dog'],\n",
    "                          ['her dog rarely barks','dog'],\n",
    "                          ['barking dogs don\\'t bite','dog'],\n",
    "                          ['cats are anti-social animals','cat'],\n",
    "                          ['a cat snores','cat'], \n",
    "                          ['my pet sleeps all day long', 'cat'],\n",
    "                          ['his pet is not a social animal','cat'],\n",
    "                          ['tom snores a lot','cat'],\n",
    "                          ['her cat barks','cat'],\n",
    "                          ['cats sleep over 12 hours a day','cat']\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppers = stoppers +['pet', 'bob', 'tom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_txt = [clean_and_tokenize(text) for text in training_data[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer=\"word\",\n",
    "                        sublinear_tf=True, \n",
    "                        use_idf=True)\n",
    "\n",
    "features = tfidf.fit_transform(stemmed_txt).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = training_data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in dictionary:21\n",
      "Top 10 most frequent words:\n",
      "\t> stop\n",
      "\t> friendli\n",
      "\t> dog\n",
      "\t> not\n",
      "\t> soci\n",
      "\t> long\n",
      "\t> social\n",
      "\t> lot\n",
      "\t> hour\n",
      "\t> anim\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total words in dictionary:{len(tfidf.vocabulary_)}\")\n",
    "print(f\"Top 10 most frequent words:\")\n",
    "top_10= sorted(tfidf.vocabulary_, key=lambda x: x[1],reverse=True)[:10]\n",
    "print(\"\\t> \"+\"\\n\\t> \".join(top_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=1123, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50,min_samples_split=2,random_state=1123)\n",
    "cross_validate(clf, features, labels, cv=4)\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array([\n",
    "    ['Max always wags his tail when I arrive home. He is really friendly.','dog'],\n",
    "    ['Sophie is always sleeping when I arrive home. She is not much into socialization.','cat'],\n",
    "    ['Bob is so old that he can not do anything else but sleep','dog'],\n",
    "    ['I like friendly animals. All-day-sleeping pets is not my thing.','cat'],\n",
    "    ['Bob\\'s. snoring is weird. He might be sick.','cat'],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [clean_and_tokenize(text) for text in test_data[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max always wags his tail when I arrive home. He is really friendly.\n",
      "Cat:0.32| Dog: 0.68\n",
      "\n",
      "Sophie is always sleeping when I arrive home. She is not much into socialization.\n",
      "Cat:0.76| Dog: 0.24\n",
      "\n",
      "Bob is so old that he can not do anything else but sleep\n",
      "Cat:0.54| Dog: 0.46\n",
      "\n",
      "I like friendly animals. All-day-sleeping pets is not my thing.\n",
      "Cat:0.74| Dog: 0.26\n",
      "\n",
      "Bob's. snoring is weird. He might be sick.\n",
      "Cat:0.76| Dog: 0.24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proba = clf.predict_proba(X_test)\n",
    "for i in range(test_data.shape[0]):\n",
    "    print(test_data[i][0])\n",
    "    print(f\"Cat:{proba[i][0]}| Dog: {proba[i][1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.75      1.00      0.86         3\n",
      "         dog       1.00      0.50      0.67         2\n",
      "\n",
      "   micro avg       0.80      0.80      0.80         5\n",
      "   macro avg       0.88      0.75      0.76         5\n",
      "weighted avg       0.85      0.80      0.78         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach I: \n",
    "#### Add more samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.append(training_data, np.array([['old dogs tend to sleep for longer periods','dog'],\n",
    "                                  ['cats spend a lot of time grooming.', 'cat']]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=1123, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_txt = [clean_and_tokenize(text) for text in training_data[:,0]]\n",
    "features = tfidf.fit_transform(stemmed_txt)\n",
    "labels = training_data[:,1]\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [clean_and_tokenize(text) for text in test_data[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max always wags his tail when I arrive home. He is really friendly.\n",
      "Cat:0.4| Dog: 0.6\n",
      "\n",
      "Sophie is always sleeping when I arrive home. She is not much into socialization.\n",
      "Cat:0.74| Dog: 0.26\n",
      "\n",
      "Bob is so old that he can not do anything else but sleep\n",
      "Cat:0.66| Dog: 0.34\n",
      "\n",
      "I like friendly animals. All-day-sleeping pets is not my thing.\n",
      "Cat:0.8| Dog: 0.2\n",
      "\n",
      "Bob's. snoring is weird. He might be sick.\n",
      "Cat:0.76| Dog: 0.24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "proba = clf.predict_proba(X_test)\n",
    "for i in range(test_data.shape[0]):\n",
    "    print(test_data[i][0])\n",
    "    print(f\"Cat:{proba[i][0]}| Dog: {proba[i][1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.75      1.00      0.86         3\n",
      "         dog       1.00      0.50      0.67         2\n",
      "\n",
      "   micro avg       0.80      0.80      0.80         5\n",
      "   macro avg       0.88      0.75      0.76         5\n",
      "weighted avg       0.85      0.80      0.78         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach II:\n",
    "#### Extend test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max always wags his tail when I arrive home. He is really friendly.\n",
      "Cat:0.4| Dog: 0.6\n",
      "\n",
      "Sophie is always sleeping when I arrive home. She is not much into socialization.\n",
      "Cat:0.74| Dog: 0.26\n",
      "\n",
      "Bob is so old that he can not do anything else but sleep. He barely barks.\n",
      "Cat:0.42| Dog: 0.58\n",
      "\n",
      "I like friendly animals. All-day-sleeping pets is not my thing.\n",
      "Cat:0.8| Dog: 0.2\n",
      "\n",
      "Bob's. snoring is weird. He might be sick.\n",
      "Cat:0.76| Dog: 0.24\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       1.00      1.00      1.00         3\n",
      "         dog       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         5\n",
      "   macro avg       1.00      1.00      1.00         5\n",
      "weighted avg       1.00      1.00      1.00         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([\n",
    "    ['Max always wags his tail when I arrive home. He is really friendly.','dog'],\n",
    "    ['Sophie is always sleeping when I arrive home. She is not much into socialization.','cat'],\n",
    "    ['Bob is so old that he can not do anything else but sleep. He barely barks.','dog'],\n",
    "    ['I like friendly animals. All-day-sleeping pets is not my thing.','cat'],\n",
    "    ['Bob\\'s. snoring is weird. He might be sick.','cat'],\n",
    "])\n",
    "X_test = [clean_and_tokenize(text) for text in test_data[:,0]]\n",
    "X_test = tfidf.transform(X_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "proba = clf.predict_proba(X_test)\n",
    "for i in range(test_data.shape[0]):\n",
    "    print(test_data[i][0])\n",
    "    print(f\"Cat:{proba[i][0]}| Dog: {proba[i][1]}\\n\")\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering",
   "language": "python",
   "name": "clustering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
