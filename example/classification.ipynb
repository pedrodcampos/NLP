{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "import contractions\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "stop_punctuation = [p for p in punctuation]\n",
    "stoppers = stop_words+stop_punctuation\n",
    "stoppers.remove('not')\n",
    "\n",
    "def clean_and_tokenize(txt):\n",
    "    def get_wordnet_pos(tag):\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "        return tag_dict.get(tag[0], wordnet.NOUN)\n",
    "\n",
    "    sentences = sent_tokenize(txt)\n",
    "    cleaned_txt = []\n",
    "    for sentence in sentences:\n",
    "        expanded_sentences = contractions.fix(sentence)\n",
    "        tokens = [token for token in word_tokenize(expanded_sentences)]\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        for token, tag in tagged_tokens:\n",
    "            if len(token)>2:\n",
    "                lemma_word = lemmatizer.lemmatize(token,get_wordnet_pos(tag))\n",
    "                if lemma_word not in stoppers:\n",
    "                    stemmed_word = stemmer.stem(lemma_word)\n",
    "                    cleaned_txt.append(stemmed_word)\n",
    "    return \" \".join(cleaned_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array([['a dog barks','dog'],\n",
    "                          ['dogs are friendly animals','dog'],\n",
    "                          ['her pet won\\'t stop barking','dog'],\n",
    "                          ['bob is waggling his tail','dog'],\n",
    "                          ['her dog rarely barks','dog'],\n",
    "                          ['my dog barks','dog'],\n",
    "                          ['cats are anti-social animals','cat'],\n",
    "                          ['a cat snores','cat'], \n",
    "                          ['my pet sleeps all day long', 'cat'],\n",
    "                          ['his pet is not really social','cat'],\n",
    "                          ['tom snores a lot','cat'],\n",
    "                          ['her cat barks','cat']\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppers = stoppers +['pet', 'bob', 'tom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_txt = [clean_and_tokenize(text) for text in training_data[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer=\"word\",\n",
    "                       sublinear_tf=True, \n",
    "                        use_idf=True,\n",
    "                        norm='l2',\n",
    "                        ngram_range=(1,2))\n",
    "\n",
    "features = tfidf.fit_transform(stemmed_txt).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = training_data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in dictionary:37\n",
      "Top 10 most frequent words:\n",
      "\t> stop\n",
      "\t> stop bark\n",
      "\t> friendli\n",
      "\t> friendli anim\n",
      "\t> dog\n",
      "\t> dog bark\n",
      "\t> dog friendli\n",
      "\t> not\n",
      "\t> not stop\n",
      "\t> dog rare\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total words in dictionary:{len(tfidf.vocabulary_)}\")\n",
    "print(f\"Top 10 most frequent words:\")\n",
    "top_10= sorted(tfidf.vocabulary_, key=lambda x: x[1],reverse=True)[:10]\n",
    "print(\"\\t> \"+\"\\n\\t> \".join(top_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrocampos/Documents/GitHub Repos/NLP/clustering/.env/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array([\n",
    "    ['Max always waggles his tail when I arrive home. He is really friendly.','dog'],\n",
    "    ['Sophie is always sleeping when I arrive home. She is not much into socialization.','cat'],\n",
    "    ['My dog is so old that he can not do anything else but sleep.','dog'],\n",
    "    ['I like friendly animals. All-day-sleeping pets is not my thing.','dog']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [clean_and_tokenize(text) for text in test_data[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.50      1.00      0.67         1\n",
      "         dog       1.00      0.67      0.80         3\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.75      0.83      0.73         4\n",
      "weighted avg       0.88      0.75      0.77         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering",
   "language": "python",
   "name": "clustering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
